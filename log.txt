------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (8640 examples) in 35.023s, Win: 7, Draw: 0, Lose: 13
[TRAIN DATA SIZE]: 8640
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 74.934s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (9230 examples) in 51.962s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 17870
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 73.493s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (8180 examples) in 39.040s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 26050
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 66.337s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (8840 examples) in 44.034s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 34890
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 72.484s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (7640 examples) in 37.994s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 42530
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 68.043s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (6440 examples) in 29.339s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 48970
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 63.919s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (7990 examples) in 43.753s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 56960
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 107.795s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (6830 examples) in 33.906s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 63790
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 65.408s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (8320 examples) in 34.649s, Win: 9, Draw: 1, Lose: 10
[TRAIN DATA SIZE]: 72110
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 70.609s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (8210 examples) in 38.668s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 74.403s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (7880 examples) in 34.349s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 11 in 87.572s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (7640 examples) in 37.215s, Win: 10, Draw: 3, Lose: 7
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 12 in 86.832s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (8020 examples) in 36.770s, Win: 14, Draw: 1, Lose: 5
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 13 in 86.485s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (6880 examples) in 31.497s, Win: 16, Draw: 0, Lose: 4
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 14 in 78.960s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (8930 examples) in 42.537s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 15 in 95.676s ------

------ Start Self-Play Iteration 16 ------
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (8640 examples) in 37.134s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 8640
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 53.424s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (9230 examples) in 44.638s, Win: 6, Draw: 1, Lose: 13
[TRAIN DATA SIZE]: 17870
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 68.691s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (8180 examples) in 39.142s, Win: 9, Draw: 1, Lose: 10
[TRAIN DATA SIZE]: 26050
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 60.890s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (8840 examples) in 40.057s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 34890
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 69.122s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (7640 examples) in 38.113s, Win: 6, Draw: 1, Lose: 13
[TRAIN DATA SIZE]: 42530
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 76.435s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (6440 examples) in 26.810s, Win: 8, Draw: 0, Lose: 12
[TRAIN DATA SIZE]: 48970
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (8640 examples) in 66.460s, Win: 7, Draw: 0, Lose: 13
[TRAIN DATA SIZE]: 8640
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 85.033s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (9230 examples) in 51.757s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 17870
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 82.124s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (8180 examples) in 42.167s, Win: 10, Draw: 1, Lose: 9
[TRAIN DATA SIZE]: 26050
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 84.661s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (8840 examples) in 43.281s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 34890
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 80.271s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (7640 examples) in 62.873s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 42530
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 126.107s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (6440 examples) in 32.068s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 48970
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 81.573s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (7990 examples) in 49.704s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 56960
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 78.849s ------

------ Start Self-Play Iteration 8 ------
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (7950 examples) in 35.294s, Win: 12, Draw: 2, Lose: 6
[TRAIN DATA SIZE]: 7950
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 57.398s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (9980 examples) in 46.924s, Win: 8, Draw: 2, Lose: 10
[TRAIN DATA SIZE]: 17930
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 66.178s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (9450 examples) in 43.913s, Win: 13, Draw: 2, Lose: 5
[TRAIN DATA SIZE]: 27380
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 105.794s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (8400 examples) in 37.422s, Win: 11, Draw: 3, Lose: 6
[TRAIN DATA SIZE]: 35780
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 112.006s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (9960 examples) in 44.181s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 45740
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose1, draw1
[EVALUATION RESULT]:(first)  win9, lose0, draw1
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 5 in 136.823s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (12560 examples) in 60.049s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 58300
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 118.639s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (12110 examples) in 58.797s, Win: 14, Draw: 1, Lose: 5
[TRAIN DATA SIZE]: 70410
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose2, draw2
[EVALUATION RESULT]:(first)  win8, lose1, draw1
[EVALUATION RESULT]:(second) win8, lose1, draw1
------ Finished Self-Play Iteration 7 in 144.588s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (11890 examples) in 54.204s, Win: 13, Draw: 0, Lose: 7
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 8 in 153.391s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (10950 examples) in 49.372s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 115.159s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (11890 examples) in 57.406s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 139.297s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (12660 examples) in 58.055s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 11 in 142.059s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (13080 examples) in 59.711s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 12 in 177.295s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (11340 examples) in 54.928s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 13 in 134.201s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (12620 examples) in 59.364s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 14 in 152.943s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (12960 examples) in 54.457s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 15 in 132.343s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (12630 examples) in 57.380s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 16 in 121.917s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (11080 examples) in 49.444s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 17 in 116.429s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (12190 examples) in 57.638s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 18 in 156.730s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (12450 examples) in 54.600s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 19 in 138.443s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (13410 examples) in 61.708s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 20 in 160.433s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (12400 examples) in 61.643s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 21 in 127.170s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (12410 examples) in 59.528s, Win: 8, Draw: 0, Lose: 12
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 22 in 136.839s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (12750 examples) in 54.399s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 23 in 121.374s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (14550 examples) in 66.677s, Win: 10, Draw: 0, Lose: 10
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 24 in 145.114s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (12560 examples) in 58.664s, Win: 11, Draw: 3, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 25 in 131.334s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (12790 examples) in 59.060s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 26 in 148.127s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (12430 examples) in 54.573s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 27 in 159.047s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (12580 examples) in 56.074s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 28 in 152.868s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (11480 examples) in 50.397s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 29 in 144.182s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (12260 examples) in 63.852s, Win: 14, Draw: 0, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win0, draw10; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 30 in 157.179s ------

[round_robin] All done.
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (7850 examples) in 36.803s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 7850
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 61.099s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (7430 examples) in 32.662s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 15280
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 51.243s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (12300 examples) in 61.174s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 27580
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 83.261s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (7190 examples) in 33.534s, Win: 11, Draw: 3, Lose: 6
[TRAIN DATA SIZE]: 34770
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 62.879s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (8300 examples) in 38.144s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 43070
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 69.245s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (7070 examples) in 34.707s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 50140
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 69.116s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (11130 examples) in 55.128s, Win: 8, Draw: 3, Lose: 9
[TRAIN DATA SIZE]: 61270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 98.778s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (7630 examples) in 32.854s, Win: 11, Draw: 2, Lose: 7
[TRAIN DATA SIZE]: 68900
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 77.019s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (7450 examples) in 32.804s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 76350
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 83.604s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (7060 examples) in 33.294s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 106.904s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (9410 examples) in 42.251s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (7850 examples) in 34.340s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 7850
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 57.887s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (7430 examples) in 32.710s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 15280
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 51.912s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (12300 examples) in 60.835s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 27580
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 83.550s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (7190 examples) in 31.945s, Win: 11, Draw: 3, Lose: 6
[TRAIN DATA SIZE]: 34770
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 62.005s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (8300 examples) in 39.184s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 43070
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 72.233s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (7070 examples) in 34.047s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 50140
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 67.640s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (11130 examples) in 49.398s, Win: 8, Draw: 3, Lose: 9
[TRAIN DATA SIZE]: 61270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 96.357s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (7630 examples) in 40.167s, Win: 11, Draw: 2, Lose: 7
[TRAIN DATA SIZE]: 68900
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 83.895s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (7450 examples) in 33.145s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 76350
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 85.215s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (7060 examples) in 34.553s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 10 in 109.826s ------

------ Start Self-Play Iteration 11 ------
------ Start Self-Play Iteration 1 ------
[AlphaZeroParallel] Finished 20 episodes (7850 examples) in 32.638s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 7850
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 1 in 56.194s ------

------ Start Self-Play Iteration 2 ------
[AlphaZeroParallel] Finished 20 episodes (7430 examples) in 34.502s, Win: 11, Draw: 0, Lose: 9
[TRAIN DATA SIZE]: 15280
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 2 in 54.247s ------

------ Start Self-Play Iteration 3 ------
[AlphaZeroParallel] Finished 20 episodes (12300 examples) in 54.337s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 27580
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 3 in 77.562s ------

------ Start Self-Play Iteration 4 ------
[AlphaZeroParallel] Finished 20 episodes (7190 examples) in 33.840s, Win: 11, Draw: 3, Lose: 6
[TRAIN DATA SIZE]: 34770
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 4 in 63.181s ------

------ Start Self-Play Iteration 5 ------
[AlphaZeroParallel] Finished 20 episodes (8300 examples) in 37.144s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 43070
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 5 in 69.866s ------

------ Start Self-Play Iteration 6 ------
[AlphaZeroParallel] Finished 20 episodes (7070 examples) in 34.846s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 50140
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 6 in 68.422s ------

------ Start Self-Play Iteration 7 ------
[AlphaZeroParallel] Finished 20 episodes (11130 examples) in 49.053s, Win: 8, Draw: 3, Lose: 9
[TRAIN DATA SIZE]: 61270
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 7 in 93.458s ------

------ Start Self-Play Iteration 8 ------
[AlphaZeroParallel] Finished 20 episodes (7630 examples) in 36.210s, Win: 11, Draw: 2, Lose: 7
[TRAIN DATA SIZE]: 68900
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 8 in 79.130s ------

------ Start Self-Play Iteration 9 ------
[AlphaZeroParallel] Finished 20 episodes (7450 examples) in 32.543s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 76350
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 9 in 83.502s ------

------ Start Self-Play Iteration 10 ------
[AlphaZeroParallel] Finished 20 episodes (7060 examples) in 36.381s, Win: 13, Draw: 1, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win15, lose4, draw1
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win7, lose2, draw1
------ Finished Self-Play Iteration 10 in 133.091s ------

------ Start Self-Play Iteration 11 ------
[AlphaZeroParallel] Finished 20 episodes (9550 examples) in 47.233s, Win: 9, Draw: 2, Lose: 9
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 11 in 138.872s ------

------ Start Self-Play Iteration 12 ------
[AlphaZeroParallel] Finished 20 episodes (10330 examples) in 50.550s, Win: 8, Draw: 2, Lose: 10
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 12 in 167.419s ------

------ Start Self-Play Iteration 13 ------
[AlphaZeroParallel] Finished 20 episodes (10380 examples) in 46.769s, Win: 8, Draw: 1, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose4, draw0
[EVALUATION RESULT]:(first)  win7, lose3, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 13 in 150.437s ------

------ Start Self-Play Iteration 14 ------
[AlphaZeroParallel] Finished 20 episodes (9870 examples) in 49.640s, Win: 9, Draw: 1, Lose: 10
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win16, lose2, draw2
[EVALUATION RESULT]:(first)  win8, lose1, draw1
[EVALUATION RESULT]:(second) win8, lose1, draw1
------ Finished Self-Play Iteration 14 in 175.286s ------

------ Start Self-Play Iteration 15 ------
[AlphaZeroParallel] Finished 20 episodes (9590 examples) in 44.341s, Win: 9, Draw: 5, Lose: 6
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win17, lose3, draw0
[EVALUATION RESULT]:(first)  win7, lose3, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 15 in 163.347s ------

------ Start Self-Play Iteration 16 ------
[AlphaZeroParallel] Finished 20 episodes (11470 examples) in 54.517s, Win: 7, Draw: 2, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win18, lose2, draw0
[EVALUATION RESULT]:(first)  win8, lose2, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 16 in 136.649s ------

------ Start Self-Play Iteration 17 ------
[AlphaZeroParallel] Finished 20 episodes (10630 examples) in 49.832s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 17 in 142.699s ------

------ Start Self-Play Iteration 18 ------
[AlphaZeroParallel] Finished 20 episodes (9160 examples) in 45.425s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 18 in 173.081s ------

------ Start Self-Play Iteration 19 ------
[AlphaZeroParallel] Finished 20 episodes (10970 examples) in 49.781s, Win: 10, Draw: 2, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win9, lose1, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 19 in 166.396s ------

------ Start Self-Play Iteration 20 ------
[AlphaZeroParallel] Finished 20 episodes (9630 examples) in 46.491s, Win: 7, Draw: 5, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 20 in 128.342s ------

------ Start Self-Play Iteration 21 ------
[AlphaZeroParallel] Finished 20 episodes (8720 examples) in 40.639s, Win: 12, Draw: 3, Lose: 5
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 21 in 146.613s ------

------ Start Self-Play Iteration 22 ------
[AlphaZeroParallel] Finished 20 episodes (8490 examples) in 39.904s, Win: 15, Draw: 1, Lose: 4
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 22 in 142.913s ------

------ Start Self-Play Iteration 23 ------
[AlphaZeroParallel] Finished 20 episodes (10380 examples) in 51.711s, Win: 14, Draw: 1, Lose: 5
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 23 in 158.510s ------

------ Start Self-Play Iteration 24 ------
[AlphaZeroParallel] Finished 20 episodes (10660 examples) in 49.630s, Win: 12, Draw: 1, Lose: 7
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 24 in 166.249s ------

------ Start Self-Play Iteration 25 ------
[AlphaZeroParallel] Finished 20 episodes (10260 examples) in 46.264s, Win: 15, Draw: 1, Lose: 4
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 25 in 131.185s ------

------ Start Self-Play Iteration 26 ------
[AlphaZeroParallel] Finished 20 episodes (10830 examples) in 59.291s, Win: 8, Draw: 0, Lose: 12
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 26 in 161.199s ------

------ Start Self-Play Iteration 27 ------
[AlphaZeroParallel] Finished 20 episodes (9880 examples) in 44.004s, Win: 12, Draw: 0, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win20, last_win0, draw0; win_rate=1.000
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win20, lose0, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win10, lose0, draw0
------ Finished Self-Play Iteration 27 in 147.052s ------

------ Start Self-Play Iteration 28 ------
[AlphaZeroParallel] Finished 20 episodes (10660 examples) in 44.880s, Win: 11, Draw: 1, Lose: 8
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win0, last_win20, draw0; win_rate=0.000
[REJECT NEW MODEL]
------ Finished Self-Play Iteration 28 in 114.093s ------

------ Start Self-Play Iteration 29 ------
[AlphaZeroParallel] Finished 20 episodes (10680 examples) in 51.886s, Win: 9, Draw: 0, Lose: 11
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 29 in 138.331s ------

------ Start Self-Play Iteration 30 ------
[AlphaZeroParallel] Finished 20 episodes (10790 examples) in 46.782s, Win: 14, Draw: 3, Lose: 3
[TRAIN DATA SIZE]: 80000
[AlphaZeroParallel] Start evaluating with last best model for 20 round
[EVALUATION RESULT]: currrent_win10, last_win10, draw0; win_rate=0.500
[ACCEPT NEW MODEL]
[AlphaZeroParallel] Start evaluating with baseline for 20 round
[EVALUATION RESULT]: win19, lose1, draw0
[EVALUATION RESULT]:(first)  win10, lose0, draw0
[EVALUATION RESULT]:(second) win9, lose1, draw0
------ Finished Self-Play Iteration 30 in 177.051s ------

[round_robin] All done.
------ Start Self-Play Iteration 1 ------
------ Start Self-Play Iteration 1 ------
